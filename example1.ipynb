{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "src = os.path.dirname(\"src\")\n",
    "clustering = os.path.dirname(\"src/clustering.py\")\n",
    "utils = os.path.dirname(\"src/utils.py\")\n",
    "\n",
    "sys.path.append(src)\n",
    "sys.path.append(utils)\n",
    "sys.path.append(clustering)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from bias_estimation import BiasEstimation\n",
    "from embeddings import Embedder\n",
    "from bert_embeddings import BertEmbedder\n",
    "\n",
    "datapath = \"data/askmen_trainsample20k.csv\" # 20,000 Comments\n",
    "\n",
    "TargetSet1 = [\"sister\" , \"female\" , \"woman\" , \"girl\" , \"daughter\" , \"she\" , \"hers\" , \"her\"]\n",
    "TargetSet2   = [\"brother\" , \"male\" , \"man\" , \"boy\" , \"son\" , \"he\" , \"his\" , \"him\"]\n",
    "\n",
    "bert_emb = BertEmbedder()\n",
    "bestimation = BiasEstimation(TargetSet1, TargetSet2, datapath, focus_column=\"Comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents...\n",
      "The expanded size of the tensor (584) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 584].  Tensor sizes: [1, 512]\n",
      "Skipping the #21 comment Total Words: 439\n",
      "The expanded size of the tensor (858) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 858].  Tensor sizes: [1, 512]\n",
      "Skipping the #128 comment Total Words: 654\n",
      "The expanded size of the tensor (875) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 875].  Tensor sizes: [1, 512]\n",
      "Skipping the #220 comment Total Words: 6\n",
      "The expanded size of the tensor (639) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 639].  Tensor sizes: [1, 512]\n",
      "Skipping the #346 comment Total Words: 496\n",
      "The expanded size of the tensor (533) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 533].  Tensor sizes: [1, 512]\n",
      "Skipping the #580 comment Total Words: 424\n",
      "The expanded size of the tensor (1117) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1117].  Tensor sizes: [1, 512]\n",
      "Skipping the #612 comment Total Words: 846\n",
      "The expanded size of the tensor (1041) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1041].  Tensor sizes: [1, 512]\n",
      "Skipping the #873 comment Total Words: 809\n",
      "The expanded size of the tensor (581) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 581].  Tensor sizes: [1, 512]\n",
      "Skipping the #900 comment Total Words: 459\n",
      "The expanded size of the tensor (851) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 851].  Tensor sizes: [1, 512]\n",
      "Skipping the #934 comment Total Words: 639\n",
      "The expanded size of the tensor (664) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 664].  Tensor sizes: [1, 512]\n",
      "Skipping the #1161 comment Total Words: 510\n",
      "The expanded size of the tensor (1163) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1163].  Tensor sizes: [1, 512]\n",
      "Skipping the #1172 comment Total Words: 861\n",
      "The expanded size of the tensor (651) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 651].  Tensor sizes: [1, 512]\n",
      "Skipping the #1578 comment Total Words: 549\n",
      "The expanded size of the tensor (702) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 702].  Tensor sizes: [1, 512]\n",
      "Skipping the #1643 comment Total Words: 548\n",
      "The expanded size of the tensor (622) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 622].  Tensor sizes: [1, 512]\n",
      "Skipping the #2301 comment Total Words: 543\n",
      "The expanded size of the tensor (1346) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1346].  Tensor sizes: [1, 512]\n",
      "Skipping the #2312 comment Total Words: 990\n",
      "The expanded size of the tensor (534) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 534].  Tensor sizes: [1, 512]\n",
      "Skipping the #2322 comment Total Words: 440\n",
      "The expanded size of the tensor (534) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 534].  Tensor sizes: [1, 512]\n",
      "Skipping the #2331 comment Total Words: 448\n",
      "The expanded size of the tensor (562) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 562].  Tensor sizes: [1, 512]\n",
      "Skipping the #2412 comment Total Words: 422\n",
      "The expanded size of the tensor (758) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 758].  Tensor sizes: [1, 512]\n",
      "Skipping the #2434 comment Total Words: 625\n",
      "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\n",
      "Skipping the #2521 comment Total Words: 1\n",
      "The expanded size of the tensor (645) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 645].  Tensor sizes: [1, 512]\n",
      "Skipping the #2905 comment Total Words: 524\n",
      "The expanded size of the tensor (525) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 525].  Tensor sizes: [1, 512]\n",
      "Skipping the #2996 comment Total Words: 428\n",
      "The expanded size of the tensor (521) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 521].  Tensor sizes: [1, 512]\n",
      "Skipping the #3389 comment Total Words: 406\n",
      "The expanded size of the tensor (607) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 607].  Tensor sizes: [1, 512]\n",
      "Skipping the #3739 comment Total Words: 474\n",
      "The expanded size of the tensor (515) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 515].  Tensor sizes: [1, 512]\n",
      "Skipping the #3874 comment Total Words: 406\n",
      "The expanded size of the tensor (797) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 797].  Tensor sizes: [1, 512]\n",
      "Skipping the #4049 comment Total Words: 658\n",
      "The expanded size of the tensor (531) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 531].  Tensor sizes: [1, 512]\n",
      "Skipping the #4357 comment Total Words: 421\n",
      "The expanded size of the tensor (556) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 556].  Tensor sizes: [1, 512]\n",
      "Skipping the #4402 comment Total Words: 475\n",
      "The expanded size of the tensor (736) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 736].  Tensor sizes: [1, 512]\n",
      "Skipping the #4422 comment Total Words: 610\n",
      "The expanded size of the tensor (783) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 783].  Tensor sizes: [1, 512]\n",
      "Skipping the #4430 comment Total Words: 611\n",
      "The expanded size of the tensor (1707) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1707].  Tensor sizes: [1, 512]\n",
      "Skipping the #4454 comment Total Words: 1326\n",
      "The expanded size of the tensor (981) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 981].  Tensor sizes: [1, 512]\n",
      "Skipping the #4525 comment Total Words: 801\n",
      "The expanded size of the tensor (658) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 658].  Tensor sizes: [1, 512]\n",
      "Skipping the #4600 comment Total Words: 554\n",
      "The expanded size of the tensor (773) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 773].  Tensor sizes: [1, 512]\n",
      "Skipping the #4779 comment Total Words: 638\n",
      "The expanded size of the tensor (736) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 736].  Tensor sizes: [1, 512]\n",
      "Skipping the #4909 comment Total Words: 602\n",
      "The expanded size of the tensor (590) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 590].  Tensor sizes: [1, 512]\n",
      "Skipping the #4988 comment Total Words: 455\n",
      "The expanded size of the tensor (1170) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1170].  Tensor sizes: [1, 512]\n",
      "Skipping the #5065 comment Total Words: 922\n",
      "The expanded size of the tensor (517) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 517].  Tensor sizes: [1, 512]\n",
      "Skipping the #5193 comment Total Words: 414\n",
      "The expanded size of the tensor (708) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 708].  Tensor sizes: [1, 512]\n",
      "Skipping the #5353 comment Total Words: 571\n",
      "The expanded size of the tensor (703) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 703].  Tensor sizes: [1, 512]\n",
      "Skipping the #5434 comment Total Words: 550\n",
      "The expanded size of the tensor (636) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 636].  Tensor sizes: [1, 512]\n",
      "Skipping the #5496 comment Total Words: 492\n",
      "The expanded size of the tensor (651) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 651].  Tensor sizes: [1, 512]\n",
      "Skipping the #5541 comment Total Words: 522\n",
      "The expanded size of the tensor (1376) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1376].  Tensor sizes: [1, 512]\n",
      "Skipping the #5553 comment Total Words: 1028\n",
      "The expanded size of the tensor (623) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 623].  Tensor sizes: [1, 512]\n",
      "Skipping the #5580 comment Total Words: 476\n",
      "The expanded size of the tensor (804) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 804].  Tensor sizes: [1, 512]\n",
      "Skipping the #5638 comment Total Words: 648\n",
      "The expanded size of the tensor (633) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 633].  Tensor sizes: [1, 512]\n",
      "Skipping the #5646 comment Total Words: 493\n",
      "The expanded size of the tensor (643) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 643].  Tensor sizes: [1, 512]\n",
      "Skipping the #5953 comment Total Words: 509\n",
      "The expanded size of the tensor (575) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 575].  Tensor sizes: [1, 512]\n",
      "Skipping the #5970 comment Total Words: 355\n",
      "The expanded size of the tensor (546) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 546].  Tensor sizes: [1, 512]\n",
      "Skipping the #6127 comment Total Words: 414\n",
      "The expanded size of the tensor (547) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 547].  Tensor sizes: [1, 512]\n",
      "Skipping the #6168 comment Total Words: 445\n",
      "The expanded size of the tensor (625) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 625].  Tensor sizes: [1, 512]\n",
      "Skipping the #6646 comment Total Words: 522\n",
      "The expanded size of the tensor (932) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 932].  Tensor sizes: [1, 512]\n",
      "Skipping the #6883 comment Total Words: 704\n",
      "The expanded size of the tensor (840) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 840].  Tensor sizes: [1, 512]\n",
      "Skipping the #7009 comment Total Words: 276\n",
      "The expanded size of the tensor (1216) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1216].  Tensor sizes: [1, 512]\n",
      "Skipping the #7074 comment Total Words: 967\n",
      "The expanded size of the tensor (676) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 676].  Tensor sizes: [1, 512]\n",
      "Skipping the #7098 comment Total Words: 464\n",
      "The expanded size of the tensor (555) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 555].  Tensor sizes: [1, 512]\n",
      "Skipping the #7115 comment Total Words: 428\n",
      "The expanded size of the tensor (565) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 565].  Tensor sizes: [1, 512]\n",
      "Skipping the #7414 comment Total Words: 420\n",
      "The expanded size of the tensor (637) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 637].  Tensor sizes: [1, 512]\n",
      "Skipping the #7494 comment Total Words: 495\n",
      "The expanded size of the tensor (525) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 525].  Tensor sizes: [1, 512]\n",
      "Skipping the #7569 comment Total Words: 413\n",
      "The expanded size of the tensor (585) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 585].  Tensor sizes: [1, 512]\n",
      "Skipping the #7773 comment Total Words: 518\n",
      "The expanded size of the tensor (835) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 835].  Tensor sizes: [1, 512]\n",
      "Skipping the #8048 comment Total Words: 607\n",
      "The expanded size of the tensor (759) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 759].  Tensor sizes: [1, 512]\n",
      "Skipping the #8337 comment Total Words: 502\n",
      "The expanded size of the tensor (773) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 773].  Tensor sizes: [1, 512]\n",
      "Skipping the #8455 comment Total Words: 605\n",
      "The expanded size of the tensor (517) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 517].  Tensor sizes: [1, 512]\n",
      "Skipping the #8743 comment Total Words: 407\n",
      "The expanded size of the tensor (533) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 533].  Tensor sizes: [1, 512]\n",
      "Skipping the #8792 comment Total Words: 287\n",
      "The expanded size of the tensor (565) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 565].  Tensor sizes: [1, 512]\n",
      "Skipping the #8885 comment Total Words: 462\n",
      "The expanded size of the tensor (525) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 525].  Tensor sizes: [1, 512]\n",
      "Skipping the #8957 comment Total Words: 399\n",
      "The expanded size of the tensor (607) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 607].  Tensor sizes: [1, 512]\n",
      "Skipping the #9189 comment Total Words: 449\n",
      "The expanded size of the tensor (843) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 843].  Tensor sizes: [1, 512]\n",
      "Skipping the #9425 comment Total Words: 735\n",
      "The expanded size of the tensor (964) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 964].  Tensor sizes: [1, 512]\n",
      "Skipping the #10106 comment Total Words: 717\n",
      "The expanded size of the tensor (582) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 582].  Tensor sizes: [1, 512]\n",
      "Skipping the #10235 comment Total Words: 155\n",
      "The expanded size of the tensor (610) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 610].  Tensor sizes: [1, 512]\n",
      "Skipping the #10455 comment Total Words: 466\n",
      "The expanded size of the tensor (608) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 608].  Tensor sizes: [1, 512]\n",
      "Skipping the #10747 comment Total Words: 435\n",
      "The expanded size of the tensor (810) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 810].  Tensor sizes: [1, 512]\n",
      "Skipping the #10754 comment Total Words: 571\n",
      "The expanded size of the tensor (812) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 812].  Tensor sizes: [1, 512]\n",
      "Skipping the #10956 comment Total Words: 633\n",
      "The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 768].  Tensor sizes: [1, 512]\n",
      "Skipping the #11189 comment Total Words: 567\n",
      "The expanded size of the tensor (581) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 581].  Tensor sizes: [1, 512]\n",
      "Skipping the #11209 comment Total Words: 463\n",
      "The expanded size of the tensor (963) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 963].  Tensor sizes: [1, 512]\n",
      "Skipping the #11312 comment Total Words: 696\n",
      "The expanded size of the tensor (944) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 944].  Tensor sizes: [1, 512]\n",
      "Skipping the #11677 comment Total Words: 771\n",
      "The expanded size of the tensor (521) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 521].  Tensor sizes: [1, 512]\n",
      "Skipping the #11951 comment Total Words: 728\n",
      "The expanded size of the tensor (766) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 766].  Tensor sizes: [1, 512]\n",
      "Skipping the #11990 comment Total Words: 629\n",
      "The expanded size of the tensor (549) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 549].  Tensor sizes: [1, 512]\n",
      "Skipping the #12105 comment Total Words: 396\n",
      "The expanded size of the tensor (643) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 643].  Tensor sizes: [1, 512]\n",
      "Skipping the #12426 comment Total Words: 539\n",
      "The expanded size of the tensor (566) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 566].  Tensor sizes: [1, 512]\n",
      "Skipping the #12627 comment Total Words: 428\n",
      "The expanded size of the tensor (544) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 544].  Tensor sizes: [1, 512]\n",
      "Skipping the #12778 comment Total Words: 402\n",
      "The expanded size of the tensor (643) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 643].  Tensor sizes: [1, 512]\n",
      "Skipping the #12790 comment Total Words: 460\n",
      "The expanded size of the tensor (754) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 754].  Tensor sizes: [1, 512]\n",
      "Skipping the #12933 comment Total Words: 596\n",
      "The expanded size of the tensor (626) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 626].  Tensor sizes: [1, 512]\n",
      "Skipping the #13189 comment Total Words: 543\n",
      "The expanded size of the tensor (549) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 549].  Tensor sizes: [1, 512]\n",
      "Skipping the #13386 comment Total Words: 448\n",
      "The expanded size of the tensor (537) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 537].  Tensor sizes: [1, 512]\n",
      "Skipping the #13591 comment Total Words: 386\n",
      "The expanded size of the tensor (553) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 553].  Tensor sizes: [1, 512]\n",
      "Skipping the #13996 comment Total Words: 456\n",
      "The expanded size of the tensor (556) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 556].  Tensor sizes: [1, 512]\n",
      "Skipping the #14014 comment Total Words: 437\n",
      "The expanded size of the tensor (873) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 873].  Tensor sizes: [1, 512]\n",
      "Skipping the #14156 comment Total Words: 668\n",
      "The expanded size of the tensor (579) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 579].  Tensor sizes: [1, 512]\n",
      "Skipping the #14160 comment Total Words: 457\n",
      "The expanded size of the tensor (850) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 850].  Tensor sizes: [1, 512]\n",
      "Skipping the #14308 comment Total Words: 650\n",
      "The expanded size of the tensor (629) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 629].  Tensor sizes: [1, 512]\n",
      "Skipping the #14640 comment Total Words: 430\n",
      "The expanded size of the tensor (579) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 579].  Tensor sizes: [1, 512]\n",
      "Skipping the #14743 comment Total Words: 426\n",
      "The expanded size of the tensor (1388) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1388].  Tensor sizes: [1, 512]\n",
      "Skipping the #14966 comment Total Words: 1121\n",
      "The expanded size of the tensor (633) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 633].  Tensor sizes: [1, 512]\n",
      "Skipping the #15026 comment Total Words: 555\n",
      "The expanded size of the tensor (1332) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1332].  Tensor sizes: [1, 512]\n",
      "Skipping the #15204 comment Total Words: 1049\n",
      "The expanded size of the tensor (576) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 576].  Tensor sizes: [1, 512]\n",
      "Skipping the #15357 comment Total Words: 455\n",
      "The expanded size of the tensor (628) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 628].  Tensor sizes: [1, 512]\n",
      "Skipping the #15421 comment Total Words: 506\n",
      "The expanded size of the tensor (1056) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1056].  Tensor sizes: [1, 512]\n",
      "Skipping the #15484 comment Total Words: 857\n",
      "The expanded size of the tensor (822) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 822].  Tensor sizes: [1, 512]\n",
      "Skipping the #16041 comment Total Words: 634\n",
      "The expanded size of the tensor (832) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 832].  Tensor sizes: [1, 512]\n",
      "Skipping the #16410 comment Total Words: 634\n",
      "The expanded size of the tensor (575) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 575].  Tensor sizes: [1, 512]\n",
      "Skipping the #16737 comment Total Words: 485\n",
      "The expanded size of the tensor (551) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 551].  Tensor sizes: [1, 512]\n",
      "Skipping the #16745 comment Total Words: 434\n"
     ]
    }
   ],
   "source": [
    "cl1, cl2 = bestimation.NBiasedWords_Bert(500, bert_embed=bert_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterwords1 = {}\n",
    "for i, cluster in enumerate((cl1)):\n",
    "    # biased words towards women\n",
    "    clusterwords1[i] = [(x, y) for x, y in cluster]\n",
    "\n",
    "clusterwords2 = {}\n",
    "for i, cluster in enumerate(cl2):\n",
    "    # biased words towards women\n",
    "    clusterwords2[i] = [(x, y) for x, y in cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('long', 0.09011045),\n",
       "  ('least', 0.10656914),\n",
       "  ('last', 0.116315365),\n",
       "  ('other', 0.14959794)],\n",
       " 1: [('bored', -0.08208537),\n",
       "  ('easier', -0.07965827),\n",
       "  ('concerned', -0.07193321),\n",
       "  ('harder', -0.06940204),\n",
       "  ('ready', 0.064661324),\n",
       "  ('dirty', 0.077266276)],\n",
       " 2: [('western', 0.040342003),\n",
       "  ('compatible', 0.04577145),\n",
       "  ('rare', 0.04615283),\n",
       "  ('religious', 0.047886908),\n",
       "  ('genetic', 0.058977604),\n",
       "  ('conservative', 0.06138462),\n",
       "  ('psychological', 0.070566505),\n",
       "  ('modern', 0.07125786),\n",
       "  ('cultural', 0.079220414),\n",
       "  ('decent', 0.08739358),\n",
       "  ('reasonable', 0.0921638),\n",
       "  ('soft', 0.12066743)],\n",
       " 3: [('simple', -0.06554636), ('cheap', 0.05956149)],\n",
       " 4: [('longer', -0.10944831),\n",
       "  ('horrible', -0.08277014),\n",
       "  ('uncomfortable', -0.06493375),\n",
       "  ('aware', -0.047472417)],\n",
       " 5: [('stronger', -0.08214554),\n",
       "  ('bigger', -0.070863664),\n",
       "  ('academic', -0.05800408),\n",
       "  ('fewer', -0.05759555),\n",
       "  ('higher', -0.054968894),\n",
       "  ('larger', -0.054136634),\n",
       "  ('happier', -0.041932464),\n",
       "  ('shorter', 0.057113796),\n",
       "  ('brown', 0.0647662),\n",
       "  ('smaller', 0.06821549)],\n",
       " 6: [('immature', 0.07284385), ('shitty', 0.11953649)],\n",
       " 7: [('handsome', -0.12945625),\n",
       "  ('intimate', -0.11450696),\n",
       "  ('attractive', -0.11178857),\n",
       "  ('penis', -0.107506454),\n",
       "  ('interested', -0.10593775),\n",
       "  ('intelligent', -0.105721235),\n",
       "  ('big', -0.09699157),\n",
       "  ('typical', -0.09622371),\n",
       "  ('funny', -0.090391755),\n",
       "  ('fat', -0.08565602),\n",
       "  ('taller', -0.07755607),\n",
       "  ('pleasant', -0.07400656),\n",
       "  ('stable', -0.0734036),\n",
       "  ('drunk', -0.07040143),\n",
       "  ('annoying', -0.07024717),\n",
       "  ('jealous', -0.0671384),\n",
       "  ('genuine', -0.060733795),\n",
       "  ('rich', -0.059778035),\n",
       "  ('exclusive', 0.053233743),\n",
       "  ('fresh', 0.053815365),\n",
       "  ('perfect', 0.062169492)],\n",
       " 8: [('manly', -0.12452996),\n",
       "  ('clean', -0.10899156),\n",
       "  ('excellent', -0.098097175),\n",
       "  ('same', -0.08445421),\n",
       "  ('hot', -0.083910316),\n",
       "  ('previous', -0.07106748),\n",
       "  ('second', 0.0899691)],\n",
       " 9: [('true', 0.09356937), ('holy', 0.097087085)],\n",
       " 10: [('awful', 0.04429245),\n",
       "  ('amazing', 0.08476055),\n",
       "  ('sick', 0.08599511),\n",
       "  ('whole', 0.08857992),\n",
       "  ('entire', 0.09796545)],\n",
       " 11: [('awesome', 0.06979975), ('worth', 0.09968373)],\n",
       " 12: [('depressed', -0.07149035),\n",
       "  ('teenage', -0.058496296),\n",
       "  ('bitter', 0.04579836),\n",
       "  ('desirable', 0.056667656),\n",
       "  ('major', 0.058428705),\n",
       "  ('successful', 0.060371757),\n",
       "  ('worst', 0.077010036),\n",
       "  ('satisfied', 0.08641145),\n",
       "  ('pregnant', 0.08985573),\n",
       "  ('available', 0.09222132)],\n",
       " 13: [('violent', 0.04740888),\n",
       "  ('absolute', 0.04816857),\n",
       "  ('loud', 0.04835242),\n",
       "  ('defensive', 0.06149766),\n",
       "  ('passive', 0.062140107),\n",
       "  ('emotional', 0.0654929),\n",
       "  ('financial', 0.07074186),\n",
       "  ('honest', 0.07576051),\n",
       "  ('nasty', 0.08643663),\n",
       "  ('public', 0.10040259),\n",
       "  ('minded', 0.11215502),\n",
       "  ('fake', 0.12149462)],\n",
       " 14: [('deep', -0.07221717), ('dark', -0.058873117), ('total', 0.08483085)],\n",
       " 15: [('opposite', 0.06755841),\n",
       "  ('such', 0.07493177),\n",
       "  ('similar', 0.07774347),\n",
       "  ('huge', 0.07884961),\n",
       "  ('average', 0.08831793),\n",
       "  ('non', 0.12609822),\n",
       "  ('super', 0.13750514),\n",
       "  ('female', 0.15483844)],\n",
       " 16: [('older', 0.10020316), ('younger', 0.11877322)],\n",
       " 17: [('respectful', -0.12567094),\n",
       "  ('bad', -0.11954835),\n",
       "  ('polite', -0.11888847),\n",
       "  ('sweet', -0.115279615),\n",
       "  ('fair', -0.11092964),\n",
       "  ('busy', -0.11090964),\n",
       "  ('aggressive', -0.10631713),\n",
       "  ('rough', -0.100510955),\n",
       "  ('nice', -0.09868285),\n",
       "  ('wrong', -0.08727932),\n",
       "  ('oblivious', -0.08610165),\n",
       "  ('difficult', -0.08362484),\n",
       "  ('worse', -0.08064455),\n",
       "  ('professional', -0.08001512),\n",
       "  ('gentle', -0.05317974),\n",
       "  ('ashamed', -0.03991574),\n",
       "  ('clear', 0.061152577),\n",
       "  ('anal', 0.06826502),\n",
       "  ('fast', 0.07580754),\n",
       "  ('small', 0.09888965)],\n",
       " 18: [('many', -0.10188493),\n",
       "  ('easy', -0.07508382),\n",
       "  ('impossible', -0.05174443),\n",
       "  ('easiest', -0.05136144),\n",
       "  ('unnecessary', 0.030783355),\n",
       "  ('weak', 0.059028953)],\n",
       " 19: [('helpful', -0.07999861),\n",
       "  ('enjoyable', -0.064000964),\n",
       "  ('harsh', 0.04008788),\n",
       "  ('effective', 0.047205),\n",
       "  ('quick', 0.063577354),\n",
       "  ('welcome', 0.06826419)],\n",
       " 20: [('thin', 0.067227185), ('subtle', 0.0674192), ('friendly', 0.07021093)],\n",
       " 21: [('particular', 0.08429703)],\n",
       " 22: [('damn', 0.07984683)],\n",
       " 23: [('dumb', 0.0770511)],\n",
       " 24: [('necessary', 0.055374652),\n",
       "  ('vast', 0.061195374),\n",
       "  ('empty', 0.061658144),\n",
       "  ('regular', 0.07160315),\n",
       "  ('current', 0.073429435),\n",
       "  ('slow', 0.073482424),\n",
       "  ('possible', 0.091299176),\n",
       "  ('less', 0.10565469),\n",
       "  ('much', 0.106983304)],\n",
       " 25: [('exact', 0.09004152)],\n",
       " 26: [('normal', -0.11772215),\n",
       "  ('straight', -0.11508921),\n",
       "  ('mad', -0.114748955),\n",
       "  ('cool', -0.114414394),\n",
       "  ('right', -0.10718247),\n",
       "  ('dangerous', -0.10331917),\n",
       "  ('single', -0.10257125),\n",
       "  ('most', -0.09884149),\n",
       "  ('tall', -0.097764105),\n",
       "  ('former', -0.09594312),\n",
       "  ('curious', -0.09291208),\n",
       "  ('logical', -0.09248528),\n",
       "  ('blind', -0.08738056),\n",
       "  ('important', -0.086808175),\n",
       "  ('afraid', -0.08678317),\n",
       "  ('smart', -0.08151823),\n",
       "  ('wise', -0.07904473),\n",
       "  ('odd', -0.078544915),\n",
       "  ('extra', -0.07726467),\n",
       "  ('irrelevant', -0.07693544),\n",
       "  ('thick', -0.076414645),\n",
       "  ('physical', -0.076389164),\n",
       "  ('full', -0.076060236),\n",
       "  ('latter', -0.0756343),\n",
       "  ('relevant', -0.07449734),\n",
       "  ('above', -0.07394302),\n",
       "  ('human', -0.07274544),\n",
       "  ('safe', -0.07244259),\n",
       "  ('terrible', -0.0718174),\n",
       "  ('tough', -0.07171464),\n",
       "  ('extreme', -0.071103394),\n",
       "  ('okay', -0.070948154),\n",
       "  ('correct', -0.06945634),\n",
       "  ('useless', -0.06878337),\n",
       "  ('creepy', -0.06871459),\n",
       "  ('basic', -0.06831479),\n",
       "  ('mixed', -0.06699842),\n",
       "  ('unlikely', -0.06572473),\n",
       "  ('asleep', -0.065327704),\n",
       "  ('pointless', -0.064784795),\n",
       "  ('scary', -0.06428027),\n",
       "  ('independent', -0.06361532),\n",
       "  ('sad', -0.06236422),\n",
       "  ('acceptable', -0.062250733),\n",
       "  ('expensive', -0.06198585),\n",
       "  ('warm', -0.06022322),\n",
       "  ('fantastic', -0.059991002),\n",
       "  ('weird', -0.059135973),\n",
       "  ('hilarious', -0.057233512),\n",
       "  ('heavy', -0.05722481),\n",
       "  ('desperate', -0.05653149),\n",
       "  ('irrational', -0.053943336),\n",
       "  ('careful', -0.05388531),\n",
       "  ('appropriate', -0.04658276),\n",
       "  ('accurate', -0.041817784),\n",
       "  ('complicated', -0.03725508)],\n",
       " 27: [('only', 0.1338867)],\n",
       " 28: [('sorry', 0.062537074)],\n",
       " 29: [('random', 0.07897735), ('crazy', 0.10398391)],\n",
       " 30: [('low', -0.08036056),\n",
       "  ('internal', -0.0729534),\n",
       "  ('mental', -0.07227337),\n",
       "  ('severe', 0.050171793),\n",
       "  ('vulnerable', 0.07617545)],\n",
       " 31: [('scared', -0.12224084),\n",
       "  ('lazy', -0.11179954),\n",
       "  ('more', -0.10361278),\n",
       "  ('cute', -0.101206005),\n",
       "  ('best', -0.10036251),\n",
       "  ('fine', -0.098757416),\n",
       "  ('healthy', -0.09175354),\n",
       "  ('lonely', -0.09069708),\n",
       "  ('nervous', -0.08227521),\n",
       "  ('strange', -0.06938809),\n",
       "  ('awkward', -0.0530563),\n",
       "  ('practical', -0.049686372),\n",
       "  ('third', 0.043791145),\n",
       "  ('special', 0.08221191)],\n",
       " 32: [('personal', -0.10332209),\n",
       "  ('social', -0.09979099),\n",
       "  ('complete', -0.07132521),\n",
       "  ('rational', -0.06943661),\n",
       "  ('selfish', -0.06594354),\n",
       "  ('false', 0.04224956),\n",
       "  ('unfair', 0.04390198),\n",
       "  ('wonderful', 0.048985302),\n",
       "  ('legal', 0.05068344),\n",
       "  ('trivial', 0.06494069),\n",
       "  ('stupid', 0.081723094),\n",
       "  ('natural', 0.0851782),\n",
       "  ('insane', 0.10452938),\n",
       "  ('own', 0.11497465)],\n",
       " 33: [('little', 0.105777115), ('few', 0.10677132)],\n",
       " 34: [('exciting', 0.047531992),\n",
       "  ('usual', 0.050817966),\n",
       "  ('illegal', 0.051917672),\n",
       "  ('multiple', 0.06760234),\n",
       "  ('romantic', 0.08139071),\n",
       "  ('favorite', 0.089428276),\n",
       "  ('worthless', 0.09216064),\n",
       "  ('sexy', 0.1038574)],\n",
       " 35: [('married', 0.094151676), ('old', 0.119448036)],\n",
       " 36: [('slightest', 0.082159996)],\n",
       " 37: [('cold', 0.081593305), ('black', 0.116295666)],\n",
       " 38: [('wide', 0.07534602),\n",
       "  ('young', 0.08556217),\n",
       "  ('general', 0.0927926),\n",
       "  ('various', 0.09683755),\n",
       "  ('different', 0.09984946)],\n",
       " 39: [('medical', 0.07157284)],\n",
       " 40: [('innocent', 0.04251057)],\n",
       " 41: [('silly', 0.068271935), ('ridiculous', 0.08472991)],\n",
       " 42: [('initial', 0.05073735),\n",
       "  ('original', 0.050949663),\n",
       "  ('obvious', 0.0688909),\n",
       "  ('interesting', 0.08271611)],\n",
       " 43: [('gay', -0.10967618),\n",
       "  ('bald', -0.09808442),\n",
       "  ('pro', -0.08416441),\n",
       "  ('private', -0.07540876),\n",
       "  ('anti', -0.07399368),\n",
       "  ('valid', -0.06787902),\n",
       "  ('mutual', -0.065430105),\n",
       "  ('racist', -0.06188214),\n",
       "  ('sensitive', -0.05839801),\n",
       "  ('closest', -0.057183057),\n",
       "  ('tight', -0.056864113),\n",
       "  ('solid', -0.056463987),\n",
       "  ('hardest', -0.055062592),\n",
       "  ('traditional', -0.054552317),\n",
       "  ('equal', -0.052099884),\n",
       "  ('direct', -0.04889521),\n",
       "  ('oral', -0.042875767),\n",
       "  ('main', 0.03754863),\n",
       "  ('lower', 0.04918492),\n",
       "  ('tiny', 0.075426936),\n",
       "  ('significant', 0.07648888),\n",
       "  ('naked', 0.0821577),\n",
       "  ('actual', 0.08323884),\n",
       "  ('feminine', 0.08457649),\n",
       "  ('recent', 0.09155023)],\n",
       " 44: [('skinny', 0.07478082),\n",
       "  ('local', 0.07753253),\n",
       "  ('short', 0.0859946),\n",
       "  ('poor', 0.08816275),\n",
       "  ('large', 0.097043216)],\n",
       " 45: [('dependent', 0.03863132)],\n",
       " 46: [('high', 0.0838716)],\n",
       " 47: [('sexual', 0.09567794)],\n",
       " 48: [('sure', -0.15717867),\n",
       "  ('happy', -0.13660568),\n",
       "  ('good', -0.1230261),\n",
       "  ('comfortable', -0.122166276),\n",
       "  ('great', -0.121754766),\n",
       "  ('free', -0.10823798),\n",
       "  ('upset', -0.09811056),\n",
       "  ('able', -0.09548545),\n",
       "  ('angry', -0.0922547),\n",
       "  ('guilty', -0.091578186),\n",
       "  ('common', -0.08661538),\n",
       "  ('committed', -0.086124),\n",
       "  ('strong', -0.082422525),\n",
       "  ('lucky', -0.08136615),\n",
       "  ('positive', -0.079352885),\n",
       "  ('certain', -0.07677978),\n",
       "  ('glad', -0.076494336),\n",
       "  ('unique', -0.0731163),\n",
       "  ('closer', -0.07196051),\n",
       "  ('proud', -0.07005641),\n",
       "  ('willing', -0.0683887),\n",
       "  ('conscious', -0.06721562),\n",
       "  ('capable', -0.06579998),\n",
       "  ('negative', -0.065329075),\n",
       "  ('painful', -0.061603487),\n",
       "  ('greater', -0.061230958),\n",
       "  ('biggest', -0.05678007),\n",
       "  ('popular', -0.050800085),\n",
       "  ('realistic', -0.04826659),\n",
       "  ('unable', -0.044729054),\n",
       "  ('useful', 0.07073063)],\n",
       " 49: [('specific', 0.10053706)],\n",
       " 50: [('beautiful', 0.10898939), ('gorgeous', 0.10924208)],\n",
       " 51: [('active', 0.046920598),\n",
       "  ('abusive', 0.059439123),\n",
       "  ('responsible', 0.061787963),\n",
       "  ('calm', 0.062906295),\n",
       "  ('quiet', 0.06757033),\n",
       "  ('flat', 0.06854239),\n",
       "  ('wet', 0.076627016),\n",
       "  ('several', 0.07812628),\n",
       "  ('proper', 0.078380406),\n",
       "  ('shy', 0.07883865),\n",
       "  ('blonde', 0.07924679),\n",
       "  ('occasional', 0.082161695),\n",
       "  ('serious', 0.08968234),\n",
       "  ('confident', 0.09497219),\n",
       "  ('white', 0.10202825),\n",
       "  ('ugly', 0.10824585),\n",
       "  ('red', 0.1110408),\n",
       "  ('early', 0.11145115)],\n",
       " 52: [('dead', 0.06963721), ('new', 0.11526069)],\n",
       " 53: [('next', 0.12791616)],\n",
       " 54: [('surprised', 0.07112375)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterwords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for arr in bert_emb._stored_vectors.values():\n",
    "    if np.any(np.isnan(arr) | np.isinf(arr)):\n",
    "        print(\"yes\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('skinny', 0.034409523)],\n",
       " [('lazy', -0.06392497),\n",
       "  ('straight', -0.042638958),\n",
       "  ('long', -0.039616227),\n",
       "  ('awful', -0.03324449),\n",
       "  ('black', 0.00017523766)],\n",
       " [('opposite', -0.0659647),\n",
       "  ('safe', -0.064431846),\n",
       "  ('gentle', -0.062485635),\n",
       "  ('subtle', -0.021665752),\n",
       "  ('respectful', -0.017872721),\n",
       "  ('useful', 0.02856204),\n",
       "  ('careful', 0.02925703)],\n",
       " [('comfortable', -0.09750286),\n",
       "  ('compatible', -0.04870972),\n",
       "  ('ready', -0.028151035)],\n",
       " [('tiny', -0.049832225),\n",
       "  ('natural', -0.03685808),\n",
       "  ('friendly', -0.027217329),\n",
       "  ('wrong', -0.024817824),\n",
       "  ('small', -0.019481122),\n",
       "  ('lonely', 0.029277563)],\n",
       " [('common', -0.021387666), ('similar', -0.020176142)],\n",
       " [('third', -0.08788034), ('holy', -0.015803605)],\n",
       " [('glad', 0.023909926), ('welcome', 0.06708288)],\n",
       " [('bigger', -0.045872867),\n",
       "  ('greater', -0.045592546),\n",
       "  ('larger', -0.027683794),\n",
       "  ('soft', -0.009364188)],\n",
       " [('physical', -0.0346452),\n",
       "  ('trivial', -0.023257434),\n",
       "  ('complete', -0.019709647)],\n",
       " [('above', -0.07917336),\n",
       "  ('blind', -0.056437016),\n",
       "  ('initial', -0.050638914),\n",
       "  ('new', -0.04907024),\n",
       "  ('perfect', -0.047597677),\n",
       "  ('occasional', -0.037657082),\n",
       "  ('random', -0.027947307),\n",
       "  ('pointless', -0.0017198324),\n",
       "  ('personal', -0.0012779534),\n",
       "  ('red', 0.0023059547),\n",
       "  ('typical', 0.008267611),\n",
       "  ('mutual', 0.017523468),\n",
       "  ('cute', 0.05328089),\n",
       "  ('female', 0.12576312)],\n",
       " [('naked', -0.02576232), ('lower', -0.0220415)],\n",
       " [('fantastic', -0.09391227),\n",
       "  ('oblivious', -0.07889116),\n",
       "  ('teenage', -0.07835114),\n",
       "  ('nervous', -0.07784957),\n",
       "  ('weird', -0.0653629),\n",
       "  ('such', -0.06281978),\n",
       "  ('awesome', -0.06278527),\n",
       "  ('fine', -0.06196046),\n",
       "  ('unlikely', -0.05875513),\n",
       "  ('extreme', -0.055310637),\n",
       "  ('cool', -0.05388525),\n",
       "  ('ashamed', -0.051406324),\n",
       "  ('accurate', -0.046866506),\n",
       "  ('social', -0.031749904),\n",
       "  ('mixed', -0.018560618),\n",
       "  ('normal', -0.017780244),\n",
       "  ('sexy', -0.013119429),\n",
       "  ('exclusive', -0.0079885125),\n",
       "  ('drunk', -0.0043052435),\n",
       "  ('blonde', 0.017158449)],\n",
       " [('positive', -0.053949118),\n",
       "  ('cold', -0.04440251),\n",
       "  ('racist', -0.031547576),\n",
       "  ('feminine', -0.003919959),\n",
       "  ('negative', 0.0009710789),\n",
       "  ('psychological', 0.0030764341)],\n",
       " [('logical', -0.11855212),\n",
       "  ('confident', -0.10639149),\n",
       "  ('willing', -0.08371812),\n",
       "  ('capable', -0.06798333),\n",
       "  ('stronger', -0.06277731),\n",
       "  ('effective', -0.05411926),\n",
       "  ('tough', -0.054017812),\n",
       "  ('stable', -0.05024594),\n",
       "  ('committed', -0.032161057),\n",
       "  ('passive', -0.031030476),\n",
       "  ('satisfied', -0.02267772),\n",
       "  ('solid', -0.006057143)],\n",
       " [('realistic', -0.027675092)],\n",
       " [('correct', -0.09864968),\n",
       "  ('honest', -0.07526177),\n",
       "  ('wonderful', 0.01414603),\n",
       "  ('true', 0.038194746)],\n",
       " [('second', -0.017300308),\n",
       "  ('rational', 0.0023815036),\n",
       "  ('own', 0.026841462),\n",
       "  ('responsible', 0.03353399)],\n",
       " [('great', -0.044979155),\n",
       "  ('easiest', -0.04297149),\n",
       "  ('appropriate', 0.0013651252)],\n",
       " [('more', -0.09858793), ('less', -0.08085278)],\n",
       " [('single', -0.09240529),\n",
       "  ('whole', -0.07911578),\n",
       "  ('relevant', -0.06593233),\n",
       "  ('penis', -0.06318021),\n",
       "  ('significant', -0.048968613),\n",
       "  ('possible', -0.047804654),\n",
       "  ('deep', -0.04251769),\n",
       "  ('large', -0.040914685),\n",
       "  ('academic', -0.040109664),\n",
       "  ('medical', -0.032137036),\n",
       "  ('high', -0.030371547),\n",
       "  ('active', -0.029987276),\n",
       "  ('proper', -0.02136755),\n",
       "  ('actual', -0.011882484),\n",
       "  ('genuine', -0.0010578632),\n",
       "  ('anti', -0.00044184923),\n",
       "  ('insane', 0.0035098195),\n",
       "  ('major', 0.006688148),\n",
       "  ('public', 0.0073955655),\n",
       "  ('extra', 0.009224474),\n",
       "  ('non', 0.02723527),\n",
       "  ('various', 0.038949013)],\n",
       " [('white', -0.08447039),\n",
       "  ('sexual', -0.052638352),\n",
       "  ('aggressive', -0.051710844),\n",
       "  ('gay', -0.04339868),\n",
       "  ('desperate', -0.040714234),\n",
       "  ('multiple', -0.03984362),\n",
       "  ('decent', -0.017001241),\n",
       "  ('desirable', -0.016214967),\n",
       "  ('successful', -0.009066045),\n",
       "  ('married', 0.028894722),\n",
       "  ('jealous', 0.043093085)],\n",
       " [('tight', -0.10259986),\n",
       "  ('loud', -0.08587402),\n",
       "  ('dark', -0.0737434),\n",
       "  ('bald', -0.06670439),\n",
       "  ('thick', -0.06139648),\n",
       "  ('fat', -0.060038656),\n",
       "  ('thin', -0.059992105),\n",
       "  ('taller', -0.031701863),\n",
       "  ('big', -0.017592788),\n",
       "  ('tall', -0.0041752756),\n",
       "  ('gorgeous', 0.022087038)],\n",
       " [('strong', -0.018605351),\n",
       "  ('low', -0.0122130215),\n",
       "  ('depressed', 0.0064373612)],\n",
       " [('older', -0.06014356), ('young', -0.004147023)],\n",
       " [('stupid', -0.03924012), ('dumb', 0.015561849)],\n",
       " [('warm', -0.046814978), ('hot', -0.02999422)],\n",
       " [('manly', -0.1269162),\n",
       "  ('shitty', -0.09726837),\n",
       "  ('violent', -0.09373453),\n",
       "  ('biggest', -0.081427366),\n",
       "  ('other', -0.07053271),\n",
       "  ('harsh', -0.06937593),\n",
       "  ('human', -0.054585576),\n",
       "  ('severe', -0.052541494),\n",
       "  ('wise', -0.051656097),\n",
       "  ('certain', -0.049895644),\n",
       "  ('horrible', -0.049408436),\n",
       "  ('huge', -0.049197912),\n",
       "  ('innocent', -0.04814434),\n",
       "  ('bad', -0.040341437),\n",
       "  ('abusive', -0.03601098),\n",
       "  ('conservative', -0.03560692),\n",
       "  ('good', -0.024701267),\n",
       "  ('cultural', -0.022846371),\n",
       "  ('vast', -0.014303565),\n",
       "  ('rough', -0.011863172),\n",
       "  ('dead', -0.00990659),\n",
       "  ('damn', -0.009750843),\n",
       "  ('selfish', -0.0018469989),\n",
       "  ('reasonable', -0.0010440946),\n",
       "  ('best', 0.0011980832),\n",
       "  ('fewer', 0.012649238)],\n",
       " [('upset', -0.103456736),\n",
       "  ('last', -0.064528584),\n",
       "  ('particular', -0.05730009),\n",
       "  ('nasty', -0.04894924),\n",
       "  ('brown', -0.03606075),\n",
       "  ('uncomfortable', -0.027459979),\n",
       "  ('busy', -0.022055566),\n",
       "  ('special', -0.020025492),\n",
       "  ('ugly', 0.02369234),\n",
       "  ('obvious', 0.043467373)],\n",
       " [('valid', -0.064546704), ('important', -0.06217572)],\n",
       " [('main', 0.014468074), ('only', 0.022131562)],\n",
       " [('same', 0.00926277)],\n",
       " [('pro', -0.031777233)],\n",
       " [('quick', -0.01232785)],\n",
       " [('ridiculous', -0.019668162)],\n",
       " [('asleep', -0.08823961)],\n",
       " [('empty', 0.012326419)],\n",
       " [('rich', -0.047266662),\n",
       "  ('useless', -0.04205078),\n",
       "  ('strange', -0.022772163),\n",
       "  ('unfair', -0.022501409),\n",
       "  ('worthless', -0.012153417),\n",
       "  ('poor', -0.011907816),\n",
       "  ('fresh', -0.0018197894),\n",
       "  ('smart', 0.04555303)],\n",
       " [('nice', -0.0019843578), ('flat', 0.0048680305)],\n",
       " [('entire', -0.06263757)],\n",
       " [('heavy', -0.000490129), ('regular', 0.0029631853)],\n",
       " [('harder', -0.053560138), ('easier', -0.010101616)],\n",
       " [('romantic', 0.009172827), ('least', 0.019200027)],\n",
       " [('concerned', -0.067667454), ('interested', -0.02781406)],\n",
       " [('short', -0.01347515), ('little', 0.017798454)],\n",
       " [('serious', 0.008791745),\n",
       "  ('previous', 0.032874525),\n",
       "  ('current', 0.058005273)],\n",
       " [('younger', -0.113848835),\n",
       "  ('latter', -0.11384541),\n",
       "  ('unique', -0.10773629),\n",
       "  ('enjoyable', -0.10229841),\n",
       "  ('healthy', -0.096007794),\n",
       "  ('necessary', -0.091344714),\n",
       "  ('unable', -0.09037158),\n",
       "  ('difficult', -0.08800131),\n",
       "  ('worse', -0.084837854),\n",
       "  ('equal', -0.08034474),\n",
       "  ('silly', -0.07919112),\n",
       "  ('higher', -0.07539371),\n",
       "  ('amazing', -0.07389113),\n",
       "  ('western', -0.07297093),\n",
       "  ('fair', -0.064088315),\n",
       "  ('former', -0.062423706),\n",
       "  ('awkward', -0.062036633),\n",
       "  ('cheap', -0.061010987),\n",
       "  ('smaller', -0.05953175),\n",
       "  ('vulnerable', -0.058238268),\n",
       "  ('sensitive', -0.05708003),\n",
       "  ('oral', -0.056124985),\n",
       "  ('closer', -0.052046),\n",
       "  ('available', -0.04834813),\n",
       "  ('exciting', -0.046346635),\n",
       "  ('closest', -0.0450781),\n",
       "  ('irrelevant', -0.043382347),\n",
       "  ('favorite', -0.041306496),\n",
       "  ('right', -0.035699278),\n",
       "  ('dependent', -0.03359288),\n",
       "  ('absolute', -0.027207613),\n",
       "  ('different', -0.02357608),\n",
       "  ('annoying', -0.012987822),\n",
       "  ('traditional', -0.011261702),\n",
       "  ('illegal', -0.00030201674),\n",
       "  ('anal', 0.0036502182)],\n",
       " [('scared', -0.12631184),\n",
       "  ('unnecessary', -0.10053861),\n",
       "  ('rare', -0.09915739),\n",
       "  ('handsome', -0.09614414),\n",
       "  ('religious', -0.09023619),\n",
       "  ('intimate', -0.08761865),\n",
       "  ('super', -0.08654353),\n",
       "  ('interesting', -0.0763669),\n",
       "  ('most', -0.07560903),\n",
       "  ('fake', -0.07467055),\n",
       "  ('lucky', -0.071054965),\n",
       "  ('practical', -0.06727946),\n",
       "  ('dangerous', -0.057405174),\n",
       "  ('sure', -0.050135672),\n",
       "  ('attractive', -0.04989922),\n",
       "  ('independent', -0.048223436),\n",
       "  ('usual', -0.045684576),\n",
       "  ('hardest', -0.045247078),\n",
       "  ('angry', -0.0349167),\n",
       "  ('funny', -0.0339489),\n",
       "  ('false', -0.029230714),\n",
       "  ('hilarious', -0.027879596),\n",
       "  ('general', -0.02764976),\n",
       "  ('dirty', -0.025481343),\n",
       "  ('able', -0.024952888),\n",
       "  ('sick', -0.024864674),\n",
       "  ('fast', -0.022731602),\n",
       "  ('acceptable', -0.020485282),\n",
       "  ('shy', -0.014889181),\n",
       "  ('pregnant', -0.011827886),\n",
       "  ('much', -0.009612918),\n",
       "  ('excellent', -0.0040766597),\n",
       "  ('creepy', -0.0008881092),\n",
       "  ('okay', 0.00080764294),\n",
       "  ('curious', 0.00941816),\n",
       "  ('popular', 0.020333111),\n",
       "  ('minded', 0.108627856)],\n",
       " [('irrational', -0.07943666),\n",
       "  ('happy', -0.07358211),\n",
       "  ('terrible', -0.0621123),\n",
       "  ('mad', -0.061762452),\n",
       "  ('surprised', -0.056820065),\n",
       "  ('afraid', -0.04846084),\n",
       "  ('guilty', -0.045499444),\n",
       "  ('happier', -0.042834044),\n",
       "  ('immature', -0.042792737),\n",
       "  ('conscious', -0.03884843),\n",
       "  ('proud', -0.01133579),\n",
       "  ('sorry', -0.0076942146),\n",
       "  ('sad', -0.003422618)],\n",
       " [('slightest', 0.00825879)],\n",
       " [('crazy', 0.030628115)],\n",
       " [('genetic', 0.043291032)],\n",
       " [('calm', -0.063316405),\n",
       "  ('mental', -0.060689002),\n",
       "  ('defensive', -0.044059813),\n",
       "  ('bitter', -0.03856194),\n",
       "  ('aware', -0.03674218),\n",
       "  ('clear', -0.03511393),\n",
       "  ('pleasant', -0.02562505),\n",
       "  ('legal', -0.022373646),\n",
       "  ('shorter', -0.02229175),\n",
       "  ('direct', -0.02091077),\n",
       "  ('exact', -0.020729542),\n",
       "  ('helpful', -0.016397655),\n",
       "  ('professional', -0.014763713),\n",
       "  ('intelligent', -0.0011490285),\n",
       "  ('internal', -0.00090143085),\n",
       "  ('quiet', -0.00042003393),\n",
       "  ('sweet', 0.002456367),\n",
       "  ('emotional', 0.015142322),\n",
       "  ('polite', 0.015314341),\n",
       "  ('financial', 0.018221855),\n",
       "  ('private', 0.018637031)],\n",
       " [('expensive', -0.06533986),\n",
       "  ('average', -0.056595832),\n",
       "  ('original', -0.018252194),\n",
       "  ('old', -0.0059030056)],\n",
       " [('simple', -0.11579421),\n",
       "  ('longer', -0.11197832),\n",
       "  ('clean', -0.094825566),\n",
       "  ('basic', -0.08140421),\n",
       "  ('free', -0.08102453),\n",
       "  ('modern', -0.08053833),\n",
       "  ('local', -0.080031365),\n",
       "  ('impossible', -0.072167605),\n",
       "  ('next', -0.06590244),\n",
       "  ('slow', -0.0652504),\n",
       "  ('worth', -0.06428182),\n",
       "  ('bored', -0.06275177),\n",
       "  ('wet', -0.05907911),\n",
       "  ('complicated', -0.05872169),\n",
       "  ('weak', -0.049898088),\n",
       "  ('few', -0.044485867),\n",
       "  ('total', -0.043176293),\n",
       "  ('several', -0.035362393),\n",
       "  ('easy', -0.030716538),\n",
       "  ('full', -0.029774427),\n",
       "  ('painful', -0.021917641),\n",
       "  ('wide', -0.020159006),\n",
       "  ('scary', -0.01801449),\n",
       "  ('odd', -0.01680389),\n",
       "  ('early', -0.009272069),\n",
       "  ('specific', -0.008923411),\n",
       "  ('beautiful', -0.0029858947),\n",
       "  ('recent', 0.0016002059),\n",
       "  ('many', 0.016633153),\n",
       "  ('worst', 0.079024225)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clusterwords1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('male', -0.19066203),\n",
       "  ('frustrated', -0.09322214),\n",
       "  ('helps', -0.088091314),\n",
       "  ('single', -0.081854224),\n",
       "  ('long', -0.07969886),\n",
       "  ('damn', -0.07047036),\n",
       "  ('busy', -0.06258622),\n",
       "  ('staying', -0.060316205),\n",
       "  ('opposite', -0.05696082),\n",
       "  ('6th', -0.054210246),\n",
       "  ('play', -0.04622209),\n",
       "  ('cope', -0.04602)],\n",
       " [('honest', -0.0783107),\n",
       "  ('fine', -0.076322645),\n",
       "  ('sorry', -0.06744987),\n",
       "  ('incompatible', -0.05381471),\n",
       "  ('jumping', -0.046173573)],\n",
       " [('cuts', -0.058622986),\n",
       "  ('insult', -0.051200002),\n",
       "  ('attempting', -0.049655557)],\n",
       " [('physical', -0.07317656),\n",
       "  ('fix', -0.058337778),\n",
       "  ('going', -0.052910656),\n",
       "  ('talking', -0.051628917)],\n",
       " [('blame', -0.10775632),\n",
       "  ('wants', -0.084276676),\n",
       "  ('thinks', -0.06403872),\n",
       "  ('believe', -0.05940476),\n",
       "  ('do', -0.055113494),\n",
       "  ('check', -0.054964125),\n",
       "  ('acted', -0.045962512)],\n",
       " [('chose', -0.10191029),\n",
       "  ('defeated', -0.087645054),\n",
       "  ('christian', -0.08156985),\n",
       "  ('manly', -0.07788628),\n",
       "  ('dark', -0.074082375),\n",
       "  ('confusing', -0.072747886),\n",
       "  ('gay', -0.06922972),\n",
       "  ('attack', -0.06269467),\n",
       "  ('calling', -0.062089205),\n",
       "  ('abandoning', -0.056063056),\n",
       "  ('general', -0.05604872),\n",
       "  ('separating', -0.05267179),\n",
       "  ('beneficial', -0.05046329),\n",
       "  ('exist', -0.050411403),\n",
       "  ('functioning', -0.050153762),\n",
       "  ('constitutes', -0.04910043),\n",
       "  ('enjoying', -0.047532678)],\n",
       " [('mature', -0.06328976), ('further', -0.060320362)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([101, 4830, 17644, 1998, 4223, 2099, 4995, 1005, 1056, 2008, 2524, 2000, 2224, 1010, 1045, 1049, 2025, 2307, 2012, 2068, 1006, 3471, 2007, 3262, 2652, 6782, 2073, 2125, 2028, 2711, 2059, 1996, 2279, 6229, 2027, 2128, 2035, 2908, 2026, 3274, 3772, 2039, 29082, 9597, 1007, 2021, 2065, 2017, 2079, 7929, 18168, 7020, 5807, 13382, 2151, 3277, 1012, 2310, 2074, 2042, 2725, 5760, 28516, 3503, 2123, 2131, 17531, 3218, 2045, 2024, 2111, 2182, 2061, 2108, 2583, 8046, 2051, 2003, 2204, 102, 0, 2053, 3342, 2197, 2018, 2505, 2485, 1037, 2095, 10047, 5327, 2297, 2097, 2022, 2488, 2005, 2033, 2145, 18386, 2295, 1013, 1057, 5473, 7292, 2919, 2879, 3426, 2002, 2130, 3335, 2014, 7901, 5907, 2015, 1042, 10139, 3078, 2082, 3836, 1055, 2611, 1999, 2296, 2465, 15896, 5194, 2066, 2467, 4845, 8808, 2009, 2987, 8660, 2091, 3759, 2138, 21090, 3398, 2292, 3291, 28781, 2064, 2428, 2358, 11657, 5856, 4371, 1040, 2293, 2071, 2655, 25957, 5705, 2469, 1997, 4829, 2342, 3984, 2029, 23276, 2031, 2105, 4293, 1003, 3112, 3446, 4737, 2055, 2032, 2720, 26881, 18307, 2160, 4545, 6530, 10447, 8966, 7752, 4253, 13044, 17835, 2052, 2191, 2132, 2341, 2157, 4248, 2813, 4056, 21830, 2748, 22337, 2491, 17418, 3696, 10311, 9004, 4111, 2004, 3109, 2507, 4485, 2222, 3666, 20907, 3742, 3466, 3892, 2168, 2305, 2040, 6616, 14977, 2023, 2171, 2001, 6253, 2016, 2561, 7743, 3071, 4687, 2735, 4176, 11946, 5605, 1029, 26700, 7967, 3139, 11611, 6737, 999, 1004, 14181, 1025, 2360, 4066, 3647, 2173, 2273, 20976, 2158, 6626, 8247, 7982, 6160, 5138, 2193, 9671, 21386, 2302, 2478, 2653, 8474, 2562, 2185, 3978, 2049, 2540, 18185, 6594, 2424, 2156, 3820, 2584, 2011, 4895, 11733, 14621, 9215, 21936, 16965, 18847, 24277, 3674, 7492, 2245, 2020, 28201, 2391, 4807, 5882, 2030, 4604, 2121, 16062, 4471, 2019, 4378, 2083, 5005, 4366, 7473, 23760, 18647, 7659, 2174, 2266, 3544, 2096, 2038, 2070, 5368, 3535, 3013, 27541, 2368, 19080, 10653, 2210, 2978, 2215, 4621, 3791, 4289, 2037, 18478, 2043, 7161, 8054, 2619, 2242, 5409, 2518, 3495, 17351, 15301, 12241, 6638, 2013, 2115, 2166, 1024, 12532, 10087, 6593, 4426, 2477, 15189, 2453, 3773, 2925, 4569, 2985, 3429, 26976, 2847, 2058, 1020, 2086, 8750, 2515, 13076, 2092, 12461, 2525, 7162, 2163, 2651, 4342, 4185, 2313, 17367, 2057, 2394, 6639, 5606, 17188, 2351, 2309, 2216, 4365, 2109, 2742, 2006, 9491, 3015, 2466, 2129, 2152, 2336, 5466, 9353, 9691, 2010, 2159, 2205, 2362, 2699, 2814, 2738, 13109, 5714, 6508, 8016, 6283, 6343, 7632, 8017, 3012, 8057, 2075, 2081, 3768, 2613, 3114, 18820, 4757, 3876, 2975, 11669, 8641, 5089, 4624, 2377, 5329, 12170, 1011, 4882, 2190, 25624, 2361, 14705, 12097, 3586, 3492, 9081, 14636, 12046, 5136, 2556, 2437, 2113, 2054, 2514, 2359, 2183, 17074, 17022, 4364, 2573, 2572, 4874, 2412, 2298, 2564, 6917, 2481, 2828, 2450, 2559, 2637, 9530, 23460, 2870, 2406, 27984, 8840, 2140, 4127, 2399, 9544, 15488, 4221, 6595, 2499, 4632, 9726, 10587, 3637, 7906, 15192, 10303, 1000, 20277, 3566, 4283, 2104, 25300, 3070, 2969, 7023, 4214, 16374, 2502, 2393, 5110, 4418, 5948, 2208, 2241, 2116, 2335, 3056, 2767, 9010, 14017, 22360, 28940, 2100, 2060, 3601, 2616, 15672, 2085, 7955, 4392, 3473, 3092, 19154, 3105, 2044, 2893, 2440, 3834, 4536, 2267, 2426, 2261, 10148, 13675, 27100, 2869, 18558, 5492, 3475, 4931, 3688, 3209, 11519, 4276, 2194, 9643, 2172, 4965, 15002, 2200, 3697, 17542, 2383, 2195, 2077, 13261, 5338, 4003, 2741, 2178, 2344, 5791, 16755, 9361, 2041, 1054, 3096, 16302, 4215, 29201, 3258, 2747, 8292, 22401, 17952, 13268, 4550, 8043, 11265, 4904, 22991, 2050, 1017, 1015, 26018, 3436, 2638, 3949, 11052, 9496, 6774, 6949, 9410, 3243, 2498, 2062, 10990, 2084, 4268, 3934, 2774, 11426, 2773, 2046, 18046, 2825, 6057, 2963, 3898, 18442, 2812, 2821, 2643, 2986, 2764, 18987, 6583, 22134, 2080, 3043, 8025, 2785, 7502, 7820, 11695, 2936, 2642, 14130, 2783, 3795, 8094, 16896, 2706, 2034, 8765, 3500, 8461, 3467, 7085, 13580, 6218, 7401, 2047, 21566, 2755, 8050, 2504, 4566, 4768, 2746, 14165, 4138, 2791, 2088, 2621, 8439, 14685, 17376, 2928, 8576, 10962, 2256, 4450, 2991, 2122, 12035, 2529, 3226, 3711, 2408, 11822, 7539, 10660, 17975, 5237, 4756, 1027, 1018, 3325, 2417, 23194, 4983, 11689, 19085, 2946, 2553, 4384, 4140, 3672, 8562, 2253, 3807, 2787, 2347, 4902, 2843, 2300, 2604, 2998, 2387, 4013, 2106, 13272, 3100, 3066, 11501, 9129, 2496, 2308, 2069, 3287, 8796, 2404, 8413, 13536, 2196, 2067, 4647, 2102, 9932, 7359, 2931, 5268, 2980, 2169, 3348, 12436, 20876, 9557, 2202, 2542, 2048, 4734, 6051, 2657, 18328, 3098, 3102, 6888, 9038, 2101, 2179, 2842, 2234, 2282, 9587, 4095, 14496, 26438, 2331, 3384, 17345, 12908, 7481, 15003, 6770, 13433, 15580, 5681, 5873, 14856, 2076, 2161, 27927, 2776, 7960, 3427, 22249, 2567, 3232, 3067, 3422, 28102, 2135, 22953, 11891, 21864, 15952, 9476, 27980, 9596, 2403, 19457, 2036, 2223, 9489, 2867, 2126, 8239, 3809, 11263, 2078, 2625, 5875, 3988, 3442, 2664, 2228, 5637, 13418, 6881, 22555, 2693, 3328, 3748, 2217, 2227, 5292, 26419, 2232, 2560, 9229, 2915, 2093, 3057, 13322, 12270, 14643, 2903, 2134, 2175, 8529, 7033, 2087, 6433, 6865, 3315, 3004, 10598, 2439, 2718, 2321, 2878, 2993, 3649, 7957, 5204, 9339, 3185, 5223, 3198, 2219, 5366, 5176, 2788, 7514, 3430, 6553, 2146, 5247, 2769, 3737, 4031, 2667, 3557, 2229, 1043, 2546, 2905, 3590, 3943, 8617, 6540, 2094, 3178, 3298, 2188, 2124, 2144, 26836, 9905, 4747, 20193, 3087, 20192, 24658, 3272, 2973, 8623, 2876, 2907, 2114, 7714, 4009, 2240, 8870, 7526, 18401, 12474, 2147, 7713, 29525, 4851, 2729, 18318, 18698, 15882, 10036, 2535, 2595, 3465, 10647, 22537, 4149, 5167, 12489, 3124, 2503, 2150, 22889, 3126, 7336, 15653, 6238, 4165, 13988, 28120, 2170, 5777, 6875, 2510, 13556, 11889, 2587, 5662, 5008, 3329, 2288, 3407, 2904, 3038, 5993, 15792, 3563, 2154, 4234, 10957, 9582, 3858, 6209, 2569, 3574, 1066, 2184, 2420, 28025, 26271, 3671, 2521, 7438, 21854, 11563, 1034, 5553, 2707, 4022, 4025, 4039, 5441, 17680, 3204, 4489, 2090, 2254, 2257, 2385, 16215, 3872, 14887, 2588, 26775, 20755, 3058, 5615, 2370, 7188, 3460, 2269, 2753, 2214, 6635, 2944, 8440, 4827, 5985, 12382, 10300, 5630, 3413, 4669, 2187, 3347, 2246, 2127, 22074, 4368, 4929, 4848, 2672, 8430, 3357, 5025, 2339, 2612, 2117, 11228, 6721, 3241, 2886, 3103, 20143, 2965, 28203, 2475, 6732, 2235, 3694, 2315, 6615, 5720, 2354, 5078, 5559, 14243, 4100, 5570, 16986, 3008, 12455, 6450, 8220, 4606, 2690, 21205, 16377, 2854, 3604, 2237, 13558, 5962, 13281, 2395, 19059, 3788, 6911, 15804, 14136, 3084, 5390, 9826, 14960, 2607, 2443, 3251, 6517, 5060, 4000, 3531, 3648, 2348, 15624, 6052, 12315, 6289, 6633, 13336, 1051, 9541, 12352, 11057, 8081, 19653, 18749, 12516, 3382, 3965, 2438, 6501, 23245, 8526, 2566, 4939, 7971, 3896, 16780, 15887, 10423, 28760, 4897, 2363, 7928, 21392, 7244, 7006, 2332, 3565, 7144, 15591, 2695, 2357, 4512, 15854, 6806, 2801, 4339, 3642, 5293, 5407, 14108, 2181, 4942, 6914, 2890, 2647, 4599, 3722, 3689, 3065, 2694, 4870, 5660, 6904, 2615, 3609, 6379, 15023, 8248, 18656, 3437, 10899, 7062, 2203, 2862, 8074, 22994, 2098, 2056, 3233, 3582, 2471, 3294, 16389, 10474, 4070, 3764, 2333, 5351, 5504, 2656, 4151, 3191, 2673, 5931, 2763, 3374, 3047, 6513, 5674, 2442, 27724, 5281, 4036, 5697, 7126, 2568, 11997, 2689, 2902, 2323, 22364, 5091, 3402, 4788, 3480, 3993, 5987, 9641, 3947, 2942, 3942, 1008, 2852, 25805, 22717, 19454, 28775, 3064, 6040, 2165, 8659, 24832, 2162, 3506, 4121, 2768, 2698, 2519, 3244, 12476, 22861, 3599, 1038, 1039, 3524, 18681, 1050, 12452, 3967, 7777, 2600, 1046, 6342, 6970, 14701, 17358, 2180, 4699, 4292, 3513, 7577, 8909, 20910, 5724, 3835, 3203, 1016, 8093, 2678, 6296, 6402, 2373, 9677, 5306, 6167, 4842, 3129, 2243, 2367, 12530, 6814, 4129, 15429, 23757, 8622, 14548, 14263, 2213, 2272, 2770, 5607, 3793, 7047, 2119, 5478, 4041, 6574, 8329, 7840, 8680, 19173, 23161, 5959, 13760, 5580, 12285, 3610, 6898, 3516, 5631, 3857, 17827, 4033, 2898, 3528, 5826, 23911, 5177, 3556, 17965, 3168, 5632, 13545, 3327, 6322, 2364, 5387, 12024, 2330, 13128, 3754, 10639, 3214, 18579, 2831, 21233, 4952, 4148, 5763, 2617, 2411, 3110, 4488, 4487, 9153, 13473, 16480, 3818, 27408, 17153, 3406, 5562, 9630, 19395, 24045, 5422, 7483, 3255, 2716, 16319, 16031, 2733, 2320, 3174, 2409, 3039, 4613, 7704, 4182, 11324, 4312, 2318, 22602, 12213, 14745, 2435, 4945, 5425, 9501, 3086])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_emb._stored_vectors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fu']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['she', 'is', 'so', 'fu', '##gly', '!']\n",
    "bestimation.find_adjectives(f\"{' '.join(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['na']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestimation.find_adjectives(\"I wanna smash her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"comparing/cl1.json\", \"r\") as f:\n",
    "    word_clusts1 = json.load(f)\n",
    "\n",
    "with open(\"comparing/cl2.json\", \"r\") as f:\n",
    "    word_clusts2 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_clusts1_words = []\n",
    "word_clusts2_words = []\n",
    "\n",
    "for clu in list(word_clusts1.values()):\n",
    "    word_clusts1_words.extend(clu)\n",
    "\n",
    "for clu in list(word_clusts2.values()):\n",
    "    word_clusts2_words.extend(clu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 428)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadly_correct = []\n",
    "broadly_incorrect = []\n",
    "\n",
    "cl_twords1 = []\n",
    "cl_twords2 = []\n",
    "\n",
    "for clkey1 in list(clusterwords1.values()):\n",
    "    for word, bias in clkey1:\n",
    "        cl_twords1.append((word, bias))\n",
    "        if word in word_clusts1_words:\n",
    "            broadly_correct.append((word, bias))\n",
    "        else  : broadly_incorrect.append((word, bias))\n",
    "        \n",
    "\n",
    "for clkey2 in list(clusterwords2.values()):\n",
    "    for word, bias in clkey2:\n",
    "        cl_twords2.append((word, bias))\n",
    "        if word in word_clusts2_words:\n",
    "            broadly_correct.append((word, bias))\n",
    "        else  : broadly_incorrect.append((word, bias))\n",
    "\n",
    "len(broadly_correct), len(broadly_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 0.15483844),\n",
       " ('gorgeous', 0.10924208),\n",
       " ('total', 0.08483085),\n",
       " ('slightest', 0.082159996),\n",
       " ('single', 0.07817879),\n",
       " ('red', 0.07796946),\n",
       " ('new', 0.07620534),\n",
       " ('wide', 0.07534602),\n",
       " ('possible', 0.07095796),\n",
       " ('awesome', 0.06979975)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_twords1.sort(key= lambda x : x[1], reverse=True)\n",
    "cl_twords2.sort(key= lambda x : x[1])\n",
    "cl_twords1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('handsome', -0.12945625),\n",
       " ('scared', -0.12224084),\n",
       " ('intimate', -0.11450696),\n",
       " ('lazy', -0.11179954),\n",
       " ('blind', -0.08738056),\n",
       " ('helpful', -0.07999861),\n",
       " ('easier', -0.07965827),\n",
       " ('manly', -0.07558638),\n",
       " ('skinny', -0.07358652),\n",
       " ('bad', -0.073305964)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_twords2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW THIS ARE RESULTS WHEN WE TOOK THE ARG MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('small', 0.17538291),\n",
       " ('willing', 0.17210823),\n",
       " ('able', 0.16830987),\n",
       " ('shitty', 0.16197678),\n",
       " ('okay', 0.16081986),\n",
       " ('afraid', 0.14555785),\n",
       " ('big', 0.14212963),\n",
       " ('general', 0.14062059),\n",
       " ('nasty', 0.13830277),\n",
       " ('little', 0.13802141),\n",
       " ('more', 0.13429451),\n",
       " ('female', 0.13353294),\n",
       " ('second', 0.13240117),\n",
       " ('immature', 0.13219094),\n",
       " ('useless', 0.13104948),\n",
       " ('other', 0.12793258),\n",
       " ('short', 0.12745681),\n",
       " ('crazy', 0.12648359),\n",
       " ('real', 0.125987),\n",
       " ('social', 0.122310966),\n",
       " ('whole', 0.12222424),\n",
       " ('shallow', 0.12216404),\n",
       " ('feminine', 0.12180087),\n",
       " ('dumb', 0.12077299),\n",
       " ('happy', 0.12032026),\n",
       " ('current', 0.11968964),\n",
       " ('awesome', 0.119424134),\n",
       " ('worth', 0.11856258),\n",
       " ('full', 0.117423534),\n",
       " ('early', 0.117406726),\n",
       " ('dependent', 0.11680862),\n",
       " ('beautiful', 0.115475),\n",
       " ('good', 0.115251034),\n",
       " ('fine', 0.11354482),\n",
       " ('wrong', 0.11332625),\n",
       " ('meaningful', 0.11262989),\n",
       " ('emotional', 0.112614155),\n",
       " ('jealous', 0.11253351),\n",
       " ('silly', 0.11209062),\n",
       " ('surprised', 0.1111438),\n",
       " ('different', 0.11007029),\n",
       " ('open', 0.10997659),\n",
       " ('due', 0.10980728),\n",
       " ('interesting', 0.10930127),\n",
       " ('true', 0.108995914),\n",
       " ('oral', 0.10890132),\n",
       " ('own', 0.10873783),\n",
       " ('special', 0.10833469),\n",
       " ('low', 0.107486844),\n",
       " ('unfair', 0.10695183)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_twords1.sort(key= lambda x : x[1], reverse=True)\n",
    "cl_twords2.sort(key= lambda x : x[1])\n",
    "cl_twords1[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male', -0.1591146),\n",
       " ('attractive', -0.14518857),\n",
       " ('handsome', -0.13606524),\n",
       " ('old', -0.1342377),\n",
       " ('tall', -0.1228199),\n",
       " ('gay', -0.118902445),\n",
       " ('fellow', -0.116999),\n",
       " ('right', -0.110596806),\n",
       " ('physical', -0.10990149),\n",
       " ('taller', -0.10908076),\n",
       " ('hot', -0.10201624),\n",
       " ('dominant', -0.099953264),\n",
       " ('anal', -0.09842071),\n",
       " ('busy', -0.093921065),\n",
       " ('confident', -0.09326851),\n",
       " ('best', -0.09321588),\n",
       " ('interested', -0.09280461),\n",
       " ('dark', -0.09147611),\n",
       " ('facial', -0.09015101),\n",
       " ('much', -0.09012318),\n",
       " ('masculine', -0.08999199),\n",
       " ('young', -0.08939776),\n",
       " ('black', -0.08898696),\n",
       " ('single', -0.08889866),\n",
       " ('manly', -0.088786304),\n",
       " ('bisexual', -0.0875746),\n",
       " ('ill', -0.08740538),\n",
       " ('bald', -0.08459467),\n",
       " ('white', -0.084014714),\n",
       " ('longest', -0.08365828)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_twords2[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadly_correct.sort(key= lambda x : x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(word_clusts1_words).intersection(set(word_clusts2_words)).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699619</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>This, but I think we all know not to take that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144044</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>I don't understand why some people think accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7121</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>badassery bro, such badassery! if we ever meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Well... if I break up with someone, it IS me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311381</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>No I get that, I was confused by the picture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299772</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>What about people who just find the idea of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282835</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Yeah, if I don't put in the work I don't get s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>There is a difference between being kind and b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197502</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Honestly, I'd consider going to counseling. Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>i know man that was like soooo 3 seconds ago.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subreddit                                            Comment\n",
       "699619    AskMen  This, but I think we all know not to take that...\n",
       "144044    AskMen  I don't understand why some people think accep...\n",
       "7121      AskMen  badassery bro, such badassery! if we ever meet...\n",
       "2756      AskMen  Well... if I break up with someone, it IS me. ...\n",
       "311381    AskMen    No I get that, I was confused by the picture...\n",
       "...          ...                                                ...\n",
       "299772    AskMen  What about people who just find the idea of pr...\n",
       "282835    AskMen  Yeah, if I don't put in the work I don't get s...\n",
       "4271      AskMen  There is a difference between being kind and b...\n",
       "197502    AskMen  Honestly, I'd consider going to counseling. Yo...\n",
       "1493      AskMen      i know man that was like soooo 3 seconds ago.\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tdata = pd.read_csv(\"data/test_data.csv\")\n",
    "askmen_extra = tdata[tdata.Subreddit == \"AskMen\"]\n",
    "askmen_extra = askmen_extra[[\"Subreddit\", \"Comment\"]]\n",
    "\n",
    "askmen_curr = pd.read_csv(\"data/askmen.csv\")\n",
    "askmen_curr = askmen_curr[[\"Subreddit\", \"Comment\"]]\n",
    "\n",
    "askmen_total = pd.concat([askmen_extra, askmen_curr])\n",
    "ask_main_sample = askmen_total.sample(n = 20_000)\n",
    "ask_main_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(ask_main_sample, \"data/askmen_trainsample20k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>First off, yes you should knock out that last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Do you dress \"alternatively\" or have a bunch o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372019</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Ask him what he likes. Does he want a room wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460369</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Do you also read the brother-brother ones?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494767</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Type 'The Troubles' into google.\\n\\nAs a % of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974907</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>&amp;gt;and don't back down like a pussy\\n\\nBackin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725356</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>DON'T SAY THAT WORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987414</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Lim a-&amp;gt;infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320329</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>In the dorms we would have movie night. Someho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388914</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>Please. 100% honesty with anyone is a recipe f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subreddit                                            Comment\n",
       "349       AskMen  First off, yes you should knock out that last ...\n",
       "5497      AskMen  Do you dress \"alternatively\" or have a bunch o...\n",
       "372019    AskMen  Ask him what he likes. Does he want a room wit...\n",
       "460369    AskMen         Do you also read the brother-brother ones?\n",
       "494767    AskMen  Type 'The Troubles' into google.\\n\\nAs a % of ...\n",
       "974907    AskMen  &gt;and don't back down like a pussy\\n\\nBackin...\n",
       "725356    AskMen                                DON'T SAY THAT WORD\n",
       "987414    AskMen                                 Lim a-&gt;infinity\n",
       "320329    AskMen  In the dorms we would have movie night. Someho...\n",
       "388914    AskMen  Please. 100% honesty with anyone is a recipe f..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for comment in ask_main_sample.Comment:\n",
    "    for word in comment:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
